# RAG Based Q&A Service
This project is a small, end-to-end, extractive question-answering service built to answer questions from a collection of 20 documents on industrial and machine safety. It demonstrates the improvement of a hybrid search (vector + keyword) over a baseline vector-only search.

The entire pipeline is built using free, local, CPU-only tools, from data ingestion and embedding to the final API.

## Features
Automated Document Retrieval: Downloads source PDFs from a sources.json file using Python's requests library.

Robust Ingestion Pipeline: Parses text from PDFs, intelligently chunks it into paragraphs, and loads it into a queryable database.

Baseline Vector Search: Uses a sentence-transformers model (all-MiniLM-L6-v2) and a FAISS index to find semantically relevant text chunks.

Hybrid Reranker: Improves search accuracy by blending the baseline vector score with a keyword score from SQLite's FTS5. This brings documents with specific technical terms (e.g., "ISO 13849-1") to the top.

Grounded, Extractive Answers: Provides answers directly from the source text to prevent hallucinations, with a confidence threshold to abstain when unsure.

Simple REST API: Exposes the search functionality through a single POST /ask endpoint.

## Project Structure
```
.
├── industrial-safety-pdfs/  # Downloaded PDF documents will be stored here
├── knowledge_base.db        # SQLite database with text chunks
├── faiss_index.idx          # FAISS index for vector search
├── faiss_ids.json           # Mapping from FAISS vectors to DB IDs
├── sources.json             # Initial list of document URLs
├── source_updated.json      # Generated by the download script with filenames
├── download.py      # Script to download PDFs
├── ingest.py   # Script to ingest, chunk, and load to SQLite
├── embeddings_paralled.py  # Script to generate and store embeddings using multiprocessing 
├── Search_api.py                   # The Flask API server
└── README.md
```         
### Setup and Installation
#### Clone the Repository

```
git clone https://github.com/rgabhi2526/RAG-Q-A-Service.git
cd RAG-Q-A-Service
```
#### 2. Create a Conda Environment

This project uses a specific set of libraries. A Conda environment ensures they don't conflict with other projects.

```
# Create a new environment named 'qa_env'
conda create --name qa_env python=3.10 -y

# Activate the environment
conda activate qa_env
```
#### 3. Install Python Dependencies

Install the required packages using Conda and Pip.

```
# Install PyTorch for CPU
conda install pytorch torchvision torchaudio cpuonly -c pytorch

# Install FAISS, SentenceTransformers, and Flask from conda-forge
conda install -c conda-forge faiss-cpu sentence-transformers flask

# Install other necessary libraries
pip install numpy PyMuPDF requests
```
### How to Run (Execution Flow)
Run the following scripts in order from your terminal.

#### Step 1: Prepare Documents

This script reads sources.json, downloads all 20 PDFs into the industrial-safety-pdfs/ folder using the Python requests library, and creates source_updated.json with the filenames.

```
python download.py
```
#### Step 2: Ingest PDFs and Populate the Database
This script reads the PDFs from the folder, chunks them into paragraphs, and stores them in knowledge_base.db with an FTS5 index for keyword search.

```
python ingest.py
```
#### Step 3: Create Vector Embeddings

This script reads the chunks from the database, generates vector embeddings for each one using a multiprocessing approach for speed, and saves them to faiss_index.idx.

```
python embedd_parallel.py
```
#### Step 4: Start the API Server

This command starts the Flask web server. The Q&A service is now ready to accept requests.

```
python Search_api.py
```
The server will be running at http://127.0.0.1:8000.

### API Usage
The service exposes a single endpoint: POST /ask.
```
Request Body:

q (string, required): The question you want to ask.

k (integer, optional, default: 3): The number of context chunks to return.

mode (string, optional, default: "hybrid"): The search mode. Can be "hybrid" or "baseline".
```
#### Example curl Requests

1. Easy Question (using the default hybrid mode):

```
curl -X POST http://127.0.0.1:8000/ask \
-H "Content-Type: application/json" \
-d '{
    "q": "When does the new Machinery Regulation take effect?",
    "k": 1
}'
```
2. Tricky Question (benefits from keyword search):
This query contains the specific term "cyber security," which the hybrid reranker can use to improve the result over the baseline.

```
curl -X POST http://127.0.0.1:8000/ask \
-H "Content-Type: application/json" \
-d '{
    "q": "What are the new rules for cyber security?",
    "k": 1,
    "mode": "hybrid"
}'
```
## Results: Baseline vs. Hybrid Reranker
| Question | Top Result (Baseline Search) | Top Result (Hybrid Search) | Comment |
| :--- | :--- | :--- | :--- |
| "What are the new rules for cyber security?" | A general paragraph about new safety requirements and changes in the Machinery Regulation. | The specific sentence mentioning "...the aspects of **cyber security** and artificial intelligence." | The hybrid search boosts the result containing the exact keywords "cyber security". |
| "When must machinery have CE marking?" | A chunk discussing the transition period and dates for the new Machinery Regulation. | The specific sentence: "From January 20, 2027, the **CE marking** of machinery... will be mandatory..." | The baseline finds the right topic, but the hybrid reranker pinpoints the exact sentence with the key phrase. |
| "What is the module for individual testing?" | A chunk describing different conformity assessment procedures and modules in general. | The sentence: "...the module **individual testing**” has been introduced. Here, the Notified Body tests and certifies an individual machine..." | The baseline understands "modules" and "testing", but the reranker correctly elevates the precise definition. |
## What I Learned
Building this project was a fantastic exercise in creating a practical, end-to-end NLP pipeline. My biggest technical takeaway was the clear value of hybrid search. While vector search is powerful for understanding the general meaning of a query, it can sometimes struggle with specific, technical keywords that are crucial for factual accuracy. The keyword-based FTS search is the perfect complement, acting as a high-precision tool. Learning to normalize and blend these two different scores was key to creating a system that is both semantically aware and factually precise. I also encountered and solved real-world engineering challenges, like multiprocessing deadlocks on macOS (fork vs. spawn) and the specific syntax quirks of SQLite's FTS5, which reinforced the importance of understanding the tools beyond just their basic API.

From a project perspective, this assessment highlighted the importance of grounded generation. By forcing the answers to be extractive—pulled directly from the source documents—the system is prevented from hallucinating or generating plausible but incorrect information. This principle of keeping the model's output tied to verifiable evidence is critical for building trustworthy AI systems. The process of starting with raw PDFs and ending with a functional API provided a holistic view of how data quality, chunking strategy, and retrieval accuracy all compound to determine the final quality of the user's experience.
